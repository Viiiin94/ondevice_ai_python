# -*- coding: utf-8 -*-
"""AI__exam02_introduction_of_Deeplearning2025.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kpwwsU4792Ov5aSEpoKWEQrItfn6t-d9
"""

import numpy as np

class add_graph:
  def __init__(self):
    pass

  def forward(self, x, y):
    out = x + y
    return out

  def backward(self, dout):
    dx = dout * 1
    dy = dout * 1
    return dx, dy

"""backward : 미분
  - dx = x에 대한 미분
  - dy = y에 대한 미분
"""

class mul_graph:
  def __init__(self):
    self.x = None
    self.y = None

  def forward(self, x, y):
    self.x = x
    self.y = y
    out = x * y
    return out

  def backward(self, dout):
    dx = dout * self.y
    dy = dout * self.x
    return dx, dy

class mse_graph:
  def __init__(self):
    self.loss = None
    self.x = None
    self.y = None
    self.t = None

  def forward(self, y, t):
    self.t = t # 모델의 예측 값
    self.y = y # 모델의 결과 값
    self.loss = np.mean((self.y - self.t)**2)
    return self.loss

  def backward(self, x, dout = 1):
    data_size = self.t.shape[0]
    dweight_mse = (((self.y - self.t) * x).sum() * 2) / data_size
    dbias_mse = ((self.y - self.t).sum() * 2) / data_size
    return dweight_mse, dbias_mse

apple = 100
apple_num = 2
orange = 150
orange_num = 3
tax = 1.1

mul_apple_graph = mul_graph()
mul_orange_graph = mul_graph()
add_apple_orange_graph = add_graph()
mul_tax_graph = mul_graph()

apple_price = mul_apple_graph.forward(apple, apple_num)
orange_price = mul_orange_graph.forward(orange, orange_num)
all_price = add_apple_orange_graph.forward(apple_price, orange_price)
total_price = mul_tax_graph.forward(all_price, tax)
print(total_price)

"""715.0000000000001가 나온 이유

# 부동소수점 표현 방식
- Python은 실수를 IEEE 754 표준에 따라 저장
- 컴퓨터는 소수를 2진수로 변환해서 저장하는데, 일부 십진 소수는 2진수로 정확히 표현할 수 없음
"""

dprice = 1
dtax, dall_price = mul_tax_graph.backward(dprice)
dapple_price, dorange_price = add_apple_orange_graph.backward(dall_price)
dorange_num, dorange = mul_orange_graph.backward(dorange_price)
dapple_num, dapple = mul_apple_graph.backward(dapple_price)

print(dapple, dapple_num, dorange, dorange_num, dtax)

def celsius_to_fahrenheit(x):
  return x * 1.8 + 32

weight = np.random.uniform(0, 5, 1)
print(weight)
bias = 0

data_C = np.arange(0, 100)
data_F = celsius_to_fahrenheit(data_C)

# min - max scaling
# scaled_data_C = (data_C - data_C.min()) / (data_C.max() - data_C.min())
# scaled_data_F = (data_F - data_F.min()) / (data_F.max() - data_F.min())

# 이 전이랑 비교하기 위해서 100으로 나눔
scaled_data_C = data_C / 100
scaled_data_F = data_F / 100
print(scaled_data_C)
print(scaled_data_C.shape)
print(scaled_data_F)
print(scaled_data_F.shape)

"""# 튜플에 값을 하나만 넣고 싶을 때
- a = (100,)
- print(type(a))
"""

weight_graph = mul_graph()
bias_graph = add_graph()

weight_data_C = weight_graph.forward(weight, scaled_data_C)
predict_data = bias_graph.forward(weight_data_C, bias)
print(predict_data)

dout = 1
dbias, dweighted_data = bias_graph.backward(dout)
print(dbias)
dweight, dscaled_data = weight_graph.backward(dweighted_data)
print(dweight)

mseGraph = mse_graph()
mse = mseGraph.forward(predict_data, scaled_data_F)
print(mse)

weight_mse_gradient, bias_mse_gradient = mseGraph.backward(scaled_data_C)
print(weight_mse_gradient)
print(bias_mse_gradient)

learning_rate = 0.1

learned_weight = weight - learning_rate * weight_mse_gradient * np.average(dweight)
learned_bias = bias - learning_rate * bias_mse_gradient * dbias
print(weight, learned_weight)
print(bias, learned_bias)

error_list = []
weight_list = []
bias_list = []
for i in range(1000):
  #forward
  weight_data_C = weight_graph.forward(weight, scaled_data_C)
  predict_data = bias_graph.forward(weight_data_C, bias)
  #backward
  dout = 1
  dbias, dweighted_data = bias_graph.backward(dout)
  dweight, dscaled_data = weight_graph.backward(dweighted_data)
  #mse
  mse = mseGraph.forward(predict_data, scaled_data_F)
  error_list.append(mse)
  #mse gradient
  weight_mse_gradient, bias_mse_gradient = mseGraph.backward(scaled_data_C)
  #learning
  weight = weight - learning_rate * weight_mse_gradient * np.average(dweight)
  bias = bias - learning_rate * bias_mse_gradient * dbias
  weight_list.append(weight)
  bias_list.append(bias)
print(weight, bias)

import matplotlib.pyplot as plt
plt.plot(error_list[:100])
plt.show()

plt.plot(bias_list)
plt.show()