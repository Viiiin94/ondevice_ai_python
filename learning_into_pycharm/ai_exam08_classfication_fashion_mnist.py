# -*- coding: utf-8 -*-
"""AI__exam08_classfication_fashion_mnist.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mqPsZMi4DdO6Vdi7H-nWtfQlAj1dfZWe

[**딥러닝 CNN1**](https://dotiromoook.tistory.com/19)

[**딥러닝 CNN2**](http://taewan.kim/post/cnn/)
"""

import numpy as np
import matplotlib.pyplot as plt
from keras.datasets import fashion_mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten # 뒤에 3개는 CNN이라 불림
from keras.utils import to_categorical

(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()
print(X_train.shape)
print(Y_train.shape)
print(X_test.shape)
print(Y_test.shape)

# 0 ~ 59999의 랜덤 인덱스
my_sample = np.random.randint(0, X_train.shape[0])
print(my_sample)
print(Y_train[my_sample])
plt.imshow(X_train[my_sample], cmap='gray')
plt.show()
# print(X_train[my_sample])

label = ['T-shirt', 'trouser', 'pullover', 'dress', 'coat',
         'sandal', 'shirt', 'sneaker', 'bag', 'ankle_boot']

# 위의 숫자를 10개의 인덱스와 같으면 해당 list의 인덱스가 1
y_train = to_categorical(Y_train)
y_test = to_categorical(Y_test)
print(y_train.shape)
print(y_test.shape)
print(y_train[my_sample])

x_train = X_train.reshape(60000, 28, 28, 1)
x_test = X_test.reshape(10000, 28, 28, 1)
# print(x_train[5000])
# print(X_train[5000])

# 색상은 8비트라서 255로 나눔
# 또한 입력값의 범위를 낮추기 위해서 Scaling
x_train = x_train / 255
x_test = x_test / 255
# print(x_train.shape)
# print(x_train[5000])

from keras.src.ops import MaxPool
model = Sequential()
model.add(Conv2D(32, input_shape=(28, 28, 1), activation='relu',
                 kernel_size=(3, 3), padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
model.add(Conv2D(32, activation='relu', kernel_size=(3, 3), padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))
model.summary()

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# model training 하는 곳
fit_hist = model.fit(x_train,
                     y_train,
                     epochs=15,
                     batch_size=512,
                     validation_split=0.2)

plt.plot(fit_hist.history['loss'], label='Training Loss')
plt.plot(fit_hist.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()

plt.plot(fit_hist.history['accuracy'], label='Training Accuracy')
plt.plot(fit_hist.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

score = model.evaluate(x_test, y_test)
print('Final test set accuracy', score[1])

my_sample = np.random.randint(0, X_test.shape[0])
print('actual', Y_test[my_sample], label[Y_test[my_sample]])
pred = model.predict(x_test[my_sample].reshape(1, 28, 28, 1))
print(pred)
print('predict', np.argmax(pred), label[np.argmax(pred)])
plt.imshow(X_test[my_sample], cmap='gray')
plt.show()
