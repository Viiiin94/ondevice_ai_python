# -*- coding: utf-8 -*-
"""AI__exam04_heart_disease_classfication.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M15FmS3gZc1T65a19jp5C-GkJCR0KwyK
"""

import numpy as np
import pandas as pd                     ##자료형을 효율적으로 활용하기 위한 클래스(ex:read.excel 함수를 활용)
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, Dropout

column_names = ['age','sex', 'cp','treshbps','chol','fbs','restecg','thalach',
                'exang','oldpeak','slope','ca','thal','hearDisease']
raw_data = pd.read_excel('./heart-disease.xlsx', names=column_names)
print(raw_data.head())    ## 앞의 5개까지의 데이터만 출력해주는 옵션

raw_data.head()

raw_data.tail()

raw_data.describe()

clean_data = raw_data.replace('?', np.nan)
## ? data는 인식을 못하므로 문자열 교체(? => np.nan(숫자인 nan 으로 바꿈, 결과값은 nan으로 됨))
clean_data.info()

clean_data = clean_data.dropna()    ## 전체 통계량에 영향을 주지않는 무의미한 표본갯수라 그냥 지웠음.(이 예제에선는...)
clean_data.info()

keep = column_names.pop()
print(keep)
print(column_names)

training_data = clean_data[column_names]
target_data = clean_data[[keep]]
print(training_data.head())
print(target_data.head())

print(target_data.sum())

from sklearn.preprocessing import StandardScaler
acaler = StandardScaler()
scaled_data = acaler.fit_transform(training_data)
scaled_data = pd.DataFrame(scaled_data, columns=training_data.columns)
scaled_data.head()

scaled_data.describe().T

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(scaled_data, target_data, test_size=0.2)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

model = Sequential()
model.add(Dense(512, activation='relu', input_dim=13))
model.add(Dropout(0.1)) #dense 사이에 dropout을 추가
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))
model.summary()

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy'])
fit_hist = model.fit(X_train, y_train, batch_size=32, epochs=100, validation_split=0.2, verbose = 1)

score = model.evaluate(X_test, y_test, verbose=1)
print('loss',score[0])
print('binary_accuracy',score[1])

plt.plot(fit_hist.history['binary_accuracy'])
plt.plot(fit_hist.history['val_binary_accuracy'])
plt.show()

score = model.evaluate(X_test, y_test, verbose=1)
print('loss', score[0])
print('accuracy', score[1])

from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score

pred = model.predict(X_test)
# 심장병일 경우 반반 0.5보단 보수적인 0.1로 하는 경우가 있다고 함
pred = pred > 0.5

print(confusion_matrix(y_test, pred))
print(f1_score(y_test, pred))
print(recall_score(y_test, pred))
print(precision_score(y_test, pred))

a = [1, 4, 1, 2, 4, 2, 4, 2, 3, 4, 4]
s = set(a)
print(len(s))
print(len(a))